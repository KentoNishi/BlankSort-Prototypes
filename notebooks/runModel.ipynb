{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\nC:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inNB():\n",
    "    try:\n",
    "        __IPYTHON__\n",
    "        return True\n",
    "    except NameError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=None\n",
    "vocab_size=None\n",
    "model=lambda:None\n",
    "dictionary=dict()\n",
    "stopWords=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beforeStartup():\n",
    "    if(not inNB()):\n",
    "        maybe_download(\"binaries-v2.zip\",\n",
    "                    \"https://blanksortbinaries.blob.core.windows.net/binaries/binaries-v2.zip\")\n",
    "        extract(\"binaries-v2.zip\")\n",
    "    globals()[\"model\"] = load_model(os.path.join(os.path.join(os.path.abspath(\n",
    "        ('.' if inNB() else '')+'./binaries'), \"models\"), \"classification_model.h5\"))\n",
    "    model._make_predict_function()\n",
    "    model.summary()\n",
    "    names = [\"window_size\", \"vocab_size\", \"dictionary\"]\n",
    "    for name in names:\n",
    "        with open(os.path.join(os.path.join(os.path.abspath(('.' if inNB() else '')+'./binaries'), \"pickles\"), name+\".pickle\"), \"rb\") as f:\n",
    "            globals()[name] = pickle.load(f)\n",
    "    nltk.download(\"stopwords\")\n",
    "    globals()[\"stopWords\"] = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(rankedWords):\n",
    "    return [word for word in rankedWords if word[0] not in stopWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNumbers(rankedWords):\n",
    "    return  [word for word in rankedWords if not any(char.isdigit() for char in word[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateInverseCounts(wordSequence):\n",
    "    countDict=dict()\n",
    "    for word in wordSequence:\n",
    "        if word not in countDict:\n",
    "            countDict[word]=1\n",
    "        else:\n",
    "            countDict[word]+=1\n",
    "    return [1/countDict[word] for word in wordSequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWordScores(wordSequence,tokenized):\n",
    "    wordScores=np.zeros(len(wordSequence))\n",
    "    contextCounts=np.zeros(len(wordSequence))\n",
    "    inverseCounts=generateInverseCounts(wordSequence)\n",
    "    for i in range(len(wordSequence)):\n",
    "        leftBound=max(0,i-window_size)\n",
    "        rightBound=min(len(wordSequence)-1,i+window_size)\n",
    "        contextCounts[i]=rightBound-leftBound+1\n",
    "        for k in range(i+1,rightBound+1):\n",
    "            confidence=model.predict([[wordSequence[i]],[wordSequence[k]]])\n",
    "            wordScores[i]+=confidence[0][0]\n",
    "            wordScores[k]+=confidence[0][0]\n",
    "    return ([tokenized[i],inverseCounts[i]*wordScores[i]/contextCounts[i]] for i in range(len(wordSequence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(string):\n",
    "    string=re.sub(r\"[^\\w\\s]\", ' ', string)\n",
    "    string=string.lower()\n",
    "    tokenized=string.split()\n",
    "    wordSequence=[]\n",
    "    for word in tokenized:\n",
    "        if word in dictionary:\n",
    "            wordSequence.append(dictionary[word])\n",
    "        else:\n",
    "            wordSequence.append(dictionary[\"UNK\"])\n",
    "    return wordSequence,tokenized,string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRankedList(string,**attributes):\n",
    "    string=\" \".join(string.split())\n",
    "    noNumbers=attributes[\"noNumbers\"] if \"noNumbers\" in attributes else True\n",
    "    noStopWords=attributes[\"noStopWords\"] if \"noStopWords\" in attributes else True\n",
    "    wordSequence,tokenized,string=formatData(string)\n",
    "    wordScores=findWordScores(wordSequence,tokenized)\n",
    "    wordBank={}\n",
    "    for word in wordScores:\n",
    "        if word[0] in wordBank:\n",
    "            wordBank[word[0]]=min(wordBank[word[0]],word[1])\n",
    "        else:\n",
    "            wordBank[word[0]]=word[1]\n",
    "    sortedList=sorted(wordBank.items(), key=lambda x: x[1])\n",
    "    rankedWords=[[x,y] for x,y in sortedList]\n",
    "    if noStopWords:\n",
    "        rankedWords=removeStopWords(rankedWords)\n",
    "    if noNumbers:\n",
    "        rankedWords=removeNumbers(rankedWords)\n",
    "    return rankedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printList(testCase,num=None,**attributes):\n",
    "    noNumbers=attributes[\"noNumbers\"] if \"noNumbers\" in attributes else True\n",
    "    noStopWords=attributes[\"noStopWords\"] if \"noStopWords\" in attributes else True\n",
    "    rankedWords=generateRankedList(testCase,noNumbers=noNumbers,noStopWords=noStopWords)\n",
    "    print(testCase)\n",
    "    if(num==None):\n",
    "        num=len(rankedWords)\n",
    "    else:\n",
    "        num=min(len(rankedWords),num)\n",
    "    print()\n",
    "    for i in range(num):\n",
    "        print(str(i+1)+\". \"+rankedWords[i][0]+\": \"+str(round(rankedWords[i][1],3)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "WARNING: Logging before flag parsing goes to stderr.\nW1129 14:36:02.517243 25928 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nW1129 14:36:02.535192 25928 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nW1129 14:36:02.637917 25928 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nW1129 14:36:02.637917 25928 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nW1129 14:36:02.638938 25928 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\nW1129 14:36:03.695652 25928 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nW1129 14:36:03.702634 25928 deprecation.py:323] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 1, 300)       30000000    input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 300, 1)       0           embedding[0][0]                  \n__________________________________________________________________________________________________\nreshape_2 (Reshape)             (None, 300, 1)       0           embedding[1][0]                  \n__________________________________________________________________________________________________\ndot_2 (Dot)                     (None, 1, 1)         0           reshape_1[0][0]                  \n                                                                 reshape_2[0][0]                  \n__________________________________________________________________________________________________\nreshape_3 (Reshape)             (None, 1)            0           dot_2[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1)            2           reshape_3[0][0]                  \n==================================================================================================\nTotal params: 30,000,002\nTrainable params: 30,000,002\nNon-trainable params: 0\n__________________________________________________________________________________________________\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\yoshi\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "if inNB():\n",
    "    beforeStartup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}