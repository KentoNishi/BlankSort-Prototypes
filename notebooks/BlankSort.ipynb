{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import fasttext as ft\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "model=ft.load_facebook_model(os.path.join(os.getcwd(),\"binaries/data/cc.en.300.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=3\n",
    "stemmer = nltk.wordnet.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(text):\n",
    "    text=text.lower()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_words = [stemmer.lemmatize(word) for word in tokens if word not in stops]\n",
    "    scores=dict()\n",
    "    counts=dict()\n",
    "    contextSizes=dict()\n",
    "    for i in range(len(filtered_words)):\n",
    "        counts.setdefault(filtered_words[i],0)\n",
    "        counts[filtered_words[i]]+=1\n",
    "        leftBound=max(0,i-window_size)\n",
    "        rightBound=min(len(filtered_words)-1,i+window_size)\n",
    "        contextSize=rightBound-leftBound+1\n",
    "        contextSizes.setdefault(filtered_words[i],contextSize)\n",
    "        contextSizes[filtered_words[i]]=max(contextSizes[filtered_words[i]],contextSize)\n",
    "        for j in range(i+1,rightBound+1):\n",
    "            similarity_score=model.wv.similarity(filtered_words[i],filtered_words[j])\n",
    "            similarity_score=(similarity_score+1)/2.0\n",
    "            scores.setdefault(filtered_words[i],similarity_score)\n",
    "            scores.setdefault(filtered_words[j],similarity_score)\n",
    "            scores[filtered_words[i]]=min(scores[filtered_words[i]],similarity_score)\n",
    "            scores[filtered_words[j]]=min(scores[filtered_words[j]],similarity_score)\n",
    "    wordScores=list(map(list, scores.items()))\n",
    "    for i in range(len(wordScores)):\n",
    "        wordScores[i][1]=wordScores[i][1]/(counts[wordScores[i][0]]*contextSizes[wordScores[i][0]])\n",
    "    wordScores=sorted(wordScores, key = lambda x: x[1])#,reverse=True)\n",
    "    filteredWordScores=[]\n",
    "    for word in wordScores:\n",
    "        filtered=re.sub('[^a-zA-Z]', '', word[0])\n",
    "        if(len(filtered)>2):\n",
    "            filteredWordScores.append([filtered,word[1]])\n",
    "    return filteredWordScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[['learning', 0.023836222380244482],\n ['word', 0.02452107887005522],\n ['fasttext', 0.03222315385937691],\n ['facebook', 0.03594347079550581],\n ['model', 0.03712539082126958]]"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank(\"fastText is a library for learning of word embeddings and text classification created by Facebook's AI Research lab. The model allows to create an unsupervised learning or supervised learning algorithm for obtaining vector representations for words. Facebook makes available pretrained models for 294 languages. fastText uses a neural network for word embedding.\")[:5]"
   ]
  }
 ]
}