{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<_io.TextIOWrapper name='c:\\\\Users\\\\yoshi\\\\OneDrive\\\\Documents\\\\GitHub\\\\BlankSort-Prototypes\\\\scripts\\\\runModel.py' mode='w' encoding='cp1252'>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "open(os.path.join(os.path.abspath('../scripts'),\"runModel.py\"), \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Overwriting ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile ../scripts/runModel.py\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Appending to ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile -a ../scripts/runModel.py\n",
    "model = load_model(os.path.join(os.path.join(os.path.abspath('../binaries'),\"models\"),\"classification_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Appending to ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile -a ../scripts/runModel.py\n",
    "names=[\"window_size\",\"vocab_size\",\"dictionary\"]\n",
    "for name in names:\n",
    "    with open(os.path.join(os.path.join(os.path.abspath('../binaries'),\"pickles\"),name+\".pickle\"), \"rb\") as f:\n",
    "        globals()[name]=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Appending to ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile -a ../scripts/runModel.py\n",
    "nltk.download(\"stopwords\")\n",
    "stopWords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Appending to ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile -a ../scripts/runModel.py\n",
    "def removeStopWords(rankedWords):\n",
    "    return [word for word in rankedWords if word[0] not in stopWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Appending to ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile -a ../scripts/runModel.py\n",
    "def removeNumbers(rankedWords):\n",
    "    return  [word for word in rankedWords if not any(char.isdigit() for char in word[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Appending to ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile -a ../scripts/runModel.py\n",
    "def generateInverseCounts(wordSequence):\n",
    "    countDict=dict()\n",
    "    for word in wordSequence:\n",
    "        if word not in countDict:\n",
    "            countDict[word]=1\n",
    "        else:\n",
    "            countDict[word]+=1\n",
    "    return [1/countDict[word] for word in wordSequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Appending to ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile -a ../scripts/runModel.py\n",
    "def findWordScores(wordSequence,tokenized):\n",
    "    wordScores=np.zeros(len(wordSequence))\n",
    "    contextCounts=np.zeros(len(wordSequence))\n",
    "    inverseCounts=generateInverseCounts(wordSequence)\n",
    "    for i in range(len(wordSequence)):\n",
    "        leftBound=max(0,i-window_size)\n",
    "        rightBound=min(len(wordSequence)-1,i+window_size)\n",
    "        contextCounts[i]=rightBound-leftBound+1\n",
    "        for k in range(i+1,rightBound+1):\n",
    "            confidence=model.predict([[wordSequence[i]],[wordSequence[k]]])\n",
    "            wordScores[i]+=confidence[0][0]\n",
    "            wordScores[k]+=confidence[0][0]\n",
    "    return ([tokenized[i],inverseCounts[i]*wordScores[i]/contextCounts[i]] for i in range(len(wordSequence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Appending to ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile -a ../scripts/runModel.py\n",
    "def formatData(string):\n",
    "    string=re.sub(r\"[^\\w\\s]\", ' ', string)\n",
    "    string=string.lower()\n",
    "    tokenized=string.split()\n",
    "    wordSequence=[]\n",
    "    for word in tokenized:\n",
    "        if word in dictionary:\n",
    "            wordSequence.append(dictionary[word])\n",
    "        else:\n",
    "            wordSequence.append(dictionary[\"UNK\"])\n",
    "    return wordSequence,tokenized,string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Appending to ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile -a ../scripts/runModel.py\n",
    "def generateRankedList(string,**attributes):\n",
    "    string=\" \".join(string.split())\n",
    "    noNumbers=attributes[\"noNumbers\"] if \"noNumbers\" in attributes else True\n",
    "    noStopWords=attributes[\"noStopWords\"] if \"noStopWords\" in attributes else True\n",
    "    wordSequence,tokenized,string=formatData(string)\n",
    "    wordScores=findWordScores(wordSequence,tokenized)\n",
    "    wordBank={}\n",
    "    for word in wordScores:\n",
    "        if word[0] in wordBank:\n",
    "            wordBank[word[0]]=min(wordBank[word[0]],word[1])\n",
    "        else:\n",
    "            wordBank[word[0]]=word[1]\n",
    "    sortedList=sorted(wordBank.items(), key=lambda x: x[1])\n",
    "    rankedWords=[[x,y] for x,y in sortedList]\n",
    "    if noStopWords:\n",
    "        rankedWords=removeStopWords(rankedWords)\n",
    "    if noNumbers:\n",
    "        rankedWords=removeNumbers(rankedWords)\n",
    "    return rankedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Appending to ../scripts/runModel.py\n"
    }
   ],
   "source": [
    "%%writefile -a ../scripts/runModel.py\n",
    "def printList(testCase,num=None,**attributes):\n",
    "    noNumbers=attributes[\"noNumbers\"] if \"noNumbers\" in attributes else True\n",
    "    noStopWords=attributes[\"noStopWords\"] if \"noStopWords\" in attributes else True\n",
    "    rankedWords=generateRankedList(testCase,noNumbers=noNumbers,noStopWords=noStopWords)\n",
    "    print(testCase)\n",
    "    if(num==None):\n",
    "        num=len(rankedWords)\n",
    "    else:\n",
    "        num=min(len(rankedWords),num)\n",
    "    print()\n",
    "    for i in range(num):\n",
    "        print(str(i+1)+\". \"+rankedWords[i][0]+\": \"+str(round(rankedWords[i][1],3)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "WARNING: Logging before flag parsing goes to stderr.\nW1123 15:02:56.249057 95888 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nW1123 15:02:56.285960 95888 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nW1123 15:02:56.372726 95888 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\nW1123 15:02:56.373724 95888 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\nW1123 15:02:56.373724 95888 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\nW1123 15:02:57.793874 95888 deprecation_wrapper.py:119] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\nW1123 15:02:57.799858 95888 deprecation.py:323] From C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\yoshi\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "%run ../scripts/runModel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 1, 300)       7500000     input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 300, 1)       0           embedding[0][0]                  \n__________________________________________________________________________________________________\nreshape_2 (Reshape)             (None, 300, 1)       0           embedding[1][0]                  \n__________________________________________________________________________________________________\ndot_2 (Dot)                     (None, 1, 1)         0           reshape_1[0][0]                  \n                                                                 reshape_2[0][0]                  \n__________________________________________________________________________________________________\nreshape_3 (Reshape)             (None, 1)            0           dot_2[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1)            2           reshape_3[0][0]                  \n==================================================================================================\nTotal params: 7,500,002\nTrainable params: 7,500,002\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}