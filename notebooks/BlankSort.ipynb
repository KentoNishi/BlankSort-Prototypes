{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import fasttext as ft\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\yoshi\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\yoshi\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\yoshi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n  \"C extension not loaded, training will be slow. \"\n"
    }
   ],
   "source": [
    "# https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "model=ft.load_facebook_model(os.path.join(os.getcwd(),\"binaries/data/cc.en.300.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=3\n",
    "stemmer = nltk.wordnet.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(text):\n",
    "    text=text.lower()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_words = [stemmer.lemmatize(word) for word in tokens if word not in stops]\n",
    "    scores=dict()\n",
    "    counts=dict()\n",
    "    contextSizes=dict()\n",
    "    for i in range(len(filtered_words)):\n",
    "        counts.setdefault(filtered_words[i],0)\n",
    "        counts[filtered_words[i]]+=1\n",
    "        leftBound=max(0,i-window_size)\n",
    "        rightBound=min(len(filtered_words)-1,i+window_size)\n",
    "        contextSize=rightBound-leftBound+1\n",
    "        contextSizes.setdefault(filtered_words[i],contextSize)\n",
    "        contextSizes[filtered_words[i]]=max(contextSizes[filtered_words[i]],contextSize)\n",
    "        for j in range(i+1,rightBound+1):\n",
    "            scores.setdefault(filtered_words[i],0)\n",
    "            scores.setdefault(filtered_words[j],0)\n",
    "            similarity_score=model.wv.similarity(filtered_words[i],filtered_words[j])\n",
    "            scores[filtered_words[i]]+=similarity_score\n",
    "            scores[filtered_words[j]]+=similarity_score\n",
    "    wordScores=list(map(list, scores.items()))\n",
    "    for i in range(len(wordScores)):\n",
    "        wordScores[i][1]=counts[wordScores[i][0]]*wordScores[i][1]/(contextSizes[wordScores[i][0]])\n",
    "    wordScores=sorted(wordScores, key = lambda x: x[1],reverse=True)\n",
    "    print(contextSizes)\n",
    "    return wordScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'machine': 7, 'learning': 7, '(': 6, 'ml': 7, ')': 7, 'scientific': 7, 'study': 7, 'algorithm': 7, 'statistical': 7, 'model': 7, 'computer': 7, 'system': 7, 'use': 7, 'perform': 7, 'specific': 7, 'task': 7, 'without': 7, 'using': 7, 'explicit': 7, 'instruction': 7, ',': 7, 'relying': 7, 'pattern': 7, 'inference': 7, 'instead': 7, '.': 7, 'seen': 7, 'subset': 7, 'artificial': 7, 'intelligence': 7, 'build': 7, 'mathematical': 7, 'based': 7, 'sample': 7, 'data': 7, 'known': 7, 'training': 7, 'order': 7, 'make': 7, 'prediction': 7, 'decision': 7, 'explicitly': 7, 'programmed': 7, 'used': 7, 'wide': 7, 'variety': 7, 'application': 7, 'email': 7, 'filtering': 7, 'vision': 7, 'difficult': 7, 'infeasible': 7, 'develop': 7, 'conventional': 7, 'effectively': 7, 'performing': 6}\n"
    },
    {
     "data": {
      "text/plain": "[['algorithm', 2.7868675461837222],\n [',', 1.7290706812803234],\n ['task', 1.5086108488695962],\n ['machine', 1.2603392473288946],\n ['learning', 1.158843059026237],\n ['model', 1.0156403524535043],\n ['perform', 0.7819848123139569],\n ['without', 0.7693937058959689],\n ['.', 0.6753005398703473],\n ['computer', 0.634229587657111],\n ['data', 0.5291105210781097],\n ['statistical', 0.27330892852374483],\n ['mathematical', 0.22657029437167303],\n ['specific', 0.22493657044001988],\n ['make', 0.22069273782627924],\n ['system', 0.21644370683601924],\n ['explicit', 0.21546707728079387],\n ['use', 0.2118303371327264],\n ['infeasible', 0.2078171255333083],\n ['based', 0.20232183699096953],\n ['decision', 0.19743264679397857],\n ['using', 0.19595717319420405],\n ['study', 0.19502664250986917],\n ['effectively', 0.1934394815138408],\n ['relying', 0.1860872661428792],\n ['build', 0.18284886011055537],\n ['(', 0.18081439721087614],\n [')', 0.1798313202868615],\n ['explicitly', 0.17673254225935256],\n ['instead', 0.1735897617680686],\n ['variety', 0.1715285943022796],\n ['order', 0.16747997275420598],\n ['conventional', 0.16528352882180894],\n ['used', 0.16476195199148996],\n ['application', 0.16304203176072665],\n ['programmed', 0.1620412463588374],\n ['develop', 0.16149908996054105],\n ['difficult', 0.16074246061699732],\n ['instruction', 0.159035858299051],\n ['scientific', 0.15223222405516676],\n ['wide', 0.14628232696226665],\n ['sample', 0.14519822743854352],\n ['performing', 0.14144032138089338],\n ['intelligence', 0.1388235121433224],\n ['inference', 0.13360470001186645],\n ['filtering', 0.1253383308649063],\n ['email', 0.12265826814940997],\n ['pattern', 0.12196535590503897],\n ['prediction', 0.11579700133630208],\n ['ml', 0.10197326261550188],\n ['artificial', 0.09924501953979156],\n ['training', 0.09342867827841214],\n ['vision', 0.08580111392906734],\n ['subset', 0.0760135432439191],\n ['seen', 0.052104149163434546],\n ['known', 0.033843237241464]]"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank(\"Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.\")"
   ]
  }
 ]
}